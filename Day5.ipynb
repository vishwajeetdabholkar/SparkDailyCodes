{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PySpark Window Functions\n",
    "PySpark Window functions operate on a group of rows (like frame, partition) and return a single value for every input row. PySpark SQL supports three kinds of window functions:\n",
    "\n",
    "ranking functions\n",
    "analytic functions\n",
    "aggregate functions\n",
    "\n",
    "\n",
    "To perform an operation on a group first, we need to partition the data using Window.partitionBy() , and for row number and rank function we need to additionally order by on partition data using orderBy clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Day5Spark\").master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').option('header','true').load('interview_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- (Deal ID): string (nullable = true)\n",
      " |-- (Products): string (nullable = true)\n",
      " |-- (Industry): string (nullable = true)\n",
      " |-- (Category): string (nullable = true)\n",
      " |-- (Super Region): string (nullable = true)\n",
      " |-- (Start Date): string (nullable = true)\n",
      " |-- (Term in Days): string (nullable = true)\n",
      " |-- (Amount $): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DealID: string (nullable = true)\n",
      " |-- Products: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- SuperRegion: string (nullable = true)\n",
      " |-- StartDate: string (nullable = true)\n",
      " |-- TerminDays: string (nullable = true)\n",
      " |-- Amount$: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = df.select([F.col(col).alias(col.replace('(', '')) for col in df.columns])\n",
    "df = df.select([F.col(col).alias(col.replace(')', '')) for col in df.columns])\n",
    "df = df.select([F.col(col).alias(col.replace(' ', '')) for col in df.columns])\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### row_number() window function is used to give the sequential row number starting from 1 to the result of each window partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-----------------------+--------+-----------+----------+----------+------------------+----------+\n",
      "|DealID            |Products|Industry               |Category|SuperRegion|StartDate |TerminDays|Amount$           |row_number|\n",
      "+------------------+--------+-----------------------+--------+-----------+----------+----------+------------------+----------+\n",
      "|null              |null    |null                   |null    |null       |null      |null      |null              |1         |\n",
      "|null              |null    |null                   |null    |null       |null      |null      |null              |2         |\n",
      "|null              |null    |null                   |null    |null       |null      |null      |null              |3         |\n",
      "|null              |null    |null                   |null    |null       |null      |null      |null              |4         |\n",
      "|null              |null    |null                   |null    |null       |null      |null      |null              |5         |\n",
      "|0063a00000gN5cQAAS|ANSIBLE |Financial Services     |P       |null       |2/26/2021 |1095.0    |357232.8264       |1         |\n",
      "|0063a00000gN5cQAAS|ANSIBLE |Financial Services     |P       |APAC       |2/26/2021 |1095.0    |357232.8264       |2         |\n",
      "|0063a00000gN5cQAAS|ANSIBLE |Financial Services     |P       |null       |2/26/2021 |1095.0    |445107.549775     |3         |\n",
      "|0063a00000gN5cQAAS|ANSIBLE |Financial Services     |P       |APAC       |2/26/2021 |1095.0    |445107.549775     |4         |\n",
      "|0063a00000gNaU9AAK|ANSIBLE |Media and Entertainment|C       |APAC       |9/30/2020 |365.0     |40373.125         |5         |\n",
      "|0063a00000gNal0AAC|ANSIBLE |Government             |C       |null       |9/29/2020 |365.0     |18435.177450000007|6         |\n",
      "|0063a00000gNvLjAAK|ANSIBLE |Healthcare             |P       |null       |12/31/2020|365.0     |31174.6875        |7         |\n",
      "|0063a00000gOP78AAG|ANSIBLE |Financial Services     |C       |EMEA       |9/24/2020 |365.0     |2534.916075       |8         |\n",
      "|0063a00000gOP78AAG|ANSIBLE |Financial Services     |C       |EMEA       |9/24/2020 |365.0     |2534.916075       |9         |\n",
      "|0063a00000gOSiPAAW|ANSIBLE |Government             |C       |null       |9/18/2020 |365.0     |14438.640325      |10        |\n",
      "|0063a00000gOSiPAAW|ANSIBLE |Government             |C       |null       |9/18/2020 |365.0     |14438.640325      |11        |\n",
      "|0063a00000gOSiPAAW|ANSIBLE |Government             |C       |null       |9/18/2020 |365.0     |28977.28065       |12        |\n",
      "|0063a00000gOSiPAAW|ANSIBLE |Government             |C       |null       |9/18/2020 |365.0     |28977.28065       |13        |\n",
      "|0063a00000gOU1uAAG|ANSIBLE |Government             |C       |EMEA       |9/29/2020 |365.0     |51157.961825      |14        |\n",
      "|0063a00000gOVYyAAO|ANSIBLE |Manufacturing          |C       |null       |9/29/2020 |365.0     |81186.0981        |15        |\n",
      "+------------------+--------+-----------------------+--------+-----------+----------+----------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "windowSpec  = Window.partitionBy(\"Products\").orderBy(\"DealID\")\n",
    "\n",
    "df.withColumn(\"row_number\",row_number().over(windowSpec)) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rank() window function is used to provide a rank to the result within a window partition. This function leaves gaps in rank when there are ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------------------+--------+-----------+----------+----------+------------------+----+\n",
      "|            DealID|Products|            Industry|Category|SuperRegion| StartDate|TerminDays|           Amount$|rank|\n",
      "+------------------+--------+--------------------+--------+-----------+----------+----------+------------------+----+\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|   1|\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|   1|\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|   1|\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|   1|\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|   1|\n",
      "|0063a00000gN5cQAAS| ANSIBLE|  Financial Services|       P|       null| 2/26/2021|    1095.0|       357232.8264|   1|\n",
      "|0063a00000gN5cQAAS| ANSIBLE|  Financial Services|       P|       APAC| 2/26/2021|    1095.0|       357232.8264|   1|\n",
      "|0063a00000gN5cQAAS| ANSIBLE|  Financial Services|       P|       null| 2/26/2021|    1095.0|     445107.549775|   1|\n",
      "|0063a00000gN5cQAAS| ANSIBLE|  Financial Services|       P|       APAC| 2/26/2021|    1095.0|     445107.549775|   1|\n",
      "|0063a00000gNaU9AAK| ANSIBLE|Media and Enterta...|       C|       APAC| 9/30/2020|     365.0|         40373.125|   5|\n",
      "|0063a00000gNal0AAC| ANSIBLE|          Government|       C|       null| 9/29/2020|     365.0|18435.177450000007|   6|\n",
      "|0063a00000gNvLjAAK| ANSIBLE|          Healthcare|       P|       null|12/31/2020|     365.0|        31174.6875|   7|\n",
      "|0063a00000gOP78AAG| ANSIBLE|  Financial Services|       C|       EMEA| 9/24/2020|     365.0|       2534.916075|   8|\n",
      "|0063a00000gOP78AAG| ANSIBLE|  Financial Services|       C|       EMEA| 9/24/2020|     365.0|       2534.916075|   8|\n",
      "|0063a00000gOSiPAAW| ANSIBLE|          Government|       C|       null| 9/18/2020|     365.0|      14438.640325|  10|\n",
      "|0063a00000gOSiPAAW| ANSIBLE|          Government|       C|       null| 9/18/2020|     365.0|      14438.640325|  10|\n",
      "|0063a00000gOSiPAAW| ANSIBLE|          Government|       C|       null| 9/18/2020|     365.0|       28977.28065|  10|\n",
      "|0063a00000gOSiPAAW| ANSIBLE|          Government|       C|       null| 9/18/2020|     365.0|       28977.28065|  10|\n",
      "|0063a00000gOU1uAAG| ANSIBLE|          Government|       C|       EMEA| 9/29/2020|     365.0|      51157.961825|  14|\n",
      "|0063a00000gOVYyAAO| ANSIBLE|       Manufacturing|       C|       null| 9/29/2020|     365.0|        81186.0981|  15|\n",
      "+------------------+--------+--------------------+--------+-----------+----------+----------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"rank\"\"\"\n",
    "from pyspark.sql.functions import rank\n",
    "df.withColumn(\"rank\",rank().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dense_rank() window function is used to get the result with rank of rows within a window partition without any gaps. This is similar to rank() function difference being rank function leaves gaps in rank when there are ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------------------+--------+-----------+----------+----------+------------------+----------+\n",
      "|            DealID|Products|            Industry|Category|SuperRegion| StartDate|TerminDays|           Amount$|dense_rank|\n",
      "+------------------+--------+--------------------+--------+-----------+----------+----------+------------------+----------+\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|         1|\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|         1|\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|         1|\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|         1|\n",
      "|              null|    null|                null|    null|       null|      null|      null|              null|         1|\n",
      "|0063a00000gN5cQAAS| ANSIBLE|  Financial Services|       P|       null| 2/26/2021|    1095.0|       357232.8264|         1|\n",
      "|0063a00000gN5cQAAS| ANSIBLE|  Financial Services|       P|       APAC| 2/26/2021|    1095.0|       357232.8264|         1|\n",
      "|0063a00000gN5cQAAS| ANSIBLE|  Financial Services|       P|       null| 2/26/2021|    1095.0|     445107.549775|         1|\n",
      "|0063a00000gN5cQAAS| ANSIBLE|  Financial Services|       P|       APAC| 2/26/2021|    1095.0|     445107.549775|         1|\n",
      "|0063a00000gNaU9AAK| ANSIBLE|Media and Enterta...|       C|       APAC| 9/30/2020|     365.0|         40373.125|         2|\n",
      "|0063a00000gNal0AAC| ANSIBLE|          Government|       C|       null| 9/29/2020|     365.0|18435.177450000007|         3|\n",
      "|0063a00000gNvLjAAK| ANSIBLE|          Healthcare|       P|       null|12/31/2020|     365.0|        31174.6875|         4|\n",
      "|0063a00000gOP78AAG| ANSIBLE|  Financial Services|       C|       EMEA| 9/24/2020|     365.0|       2534.916075|         5|\n",
      "|0063a00000gOP78AAG| ANSIBLE|  Financial Services|       C|       EMEA| 9/24/2020|     365.0|       2534.916075|         5|\n",
      "|0063a00000gOSiPAAW| ANSIBLE|          Government|       C|       null| 9/18/2020|     365.0|      14438.640325|         6|\n",
      "|0063a00000gOSiPAAW| ANSIBLE|          Government|       C|       null| 9/18/2020|     365.0|      14438.640325|         6|\n",
      "|0063a00000gOSiPAAW| ANSIBLE|          Government|       C|       null| 9/18/2020|     365.0|       28977.28065|         6|\n",
      "|0063a00000gOSiPAAW| ANSIBLE|          Government|       C|       null| 9/18/2020|     365.0|       28977.28065|         6|\n",
      "|0063a00000gOU1uAAG| ANSIBLE|          Government|       C|       EMEA| 9/29/2020|     365.0|      51157.961825|         7|\n",
      "|0063a00000gOVYyAAO| ANSIBLE|       Manufacturing|       C|       null| 9/29/2020|     365.0|        81186.0981|         8|\n",
      "+------------------+--------+--------------------+--------+-----------+----------+----------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"dens_rank\"\"\"\n",
    "from pyspark.sql.functions import dense_rank\n",
    "df.withColumn(\"dense_rank\",dense_rank().over(windowSpec)) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
